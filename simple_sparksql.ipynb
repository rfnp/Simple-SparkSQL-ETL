{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract: Read gz file by as a csv and convert it into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our inferred schema:\n",
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"data/fhv_tripdata_2019-01.csv.gz\")\n",
    "\n",
    "print(\"Here is our inferred schema:\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the top 20 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00001|2019-01-01 00:30:00|2019-01-01 02:51:55|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:45:00|2019-01-01 00:54:49|        null|        null|   null|                B00001|\n",
      "|              B00001|2019-01-01 00:15:00|2019-01-01 00:54:52|        null|        null|   null|                B00001|\n",
      "|              B00008|2019-01-01 00:19:00|2019-01-01 00:39:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:27:00|2019-01-01 00:37:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:48:00|2019-01-01 01:02:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:50:00|2019-01-01 00:59:00|        null|        null|   null|                B00008|\n",
      "|              B00008|2019-01-01 00:51:00|2019-01-01 00:56:00|        null|        null|   null|                B00008|\n",
      "|              B00009|2019-01-01 00:44:00|2019-01-01 00:58:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:19:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:36:00|2019-01-01 00:49:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:26:00|2019-01-01 00:32:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:26:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
      "|              B00009|2019-01-01 00:58:00|2019-01-01 01:05:00|        null|        null|   null|                B00009|\n",
      "|              B00013|2019-01-01 00:02:29|2019-01-02 00:25:30|        null|        null|   null|                B00013|\n",
      "|              B00013|2019-01-01 00:01:33|2019-01-02 00:18:16|        null|        null|   null|                B00013|\n",
      "|              B00037|2019-01-01 00:02:43|2019-01-01 00:10:14|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:26:02|2019-01-01 00:37:00|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:11:16|2019-01-01 00:25:41|        null|         265|   null|                B00037|\n",
      "|              B00037|2019-01-01 00:33:45|2019-01-01 00:45:28|        null|         265|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates or replaces a local temporary view with this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tripData\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: Filter the data as specified in the sql statement below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT * FROM tripData \\\n",
    "    WHERE (PUlocationID is NOT NULL AND \\\n",
    "    DOlocationID is NOT NULL AND \\\n",
    "    pickup_datetime >= '2019-01-01 00:00:00' AND \\\n",
    "    pickup_datetime <= '2019-01-10 23:59:59')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00254|2019-01-01 00:33:03|2019-01-01 01:37:24|         140|          52|   null|                B02356|\n",
      "|              B00254|2019-01-01 00:03:00|2019-01-01 00:34:25|         141|         237|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:45:48|2019-01-01 01:26:01|         237|         236|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:37:39|2019-01-01 01:44:59|         162|          85|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:35:06|2019-01-01 01:30:21|         237|         246|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:55:23|2019-01-01 01:48:27|         145|         224|   null|                B02882|\n",
      "|              B00254|2019-01-01 00:49:23|2019-01-01 01:38:38|         261|          14|   null|                B02994|\n",
      "|              B00254|2019-01-01 00:11:10|2019-01-01 00:44:31|         162|         233|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:00:06|2019-01-01 00:32:21|          13|          87|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:36:32|2019-01-01 01:35:54|         249|         236|   null|                B00254|\n",
      "|              B00254|2019-01-01 00:15:15|2019-01-01 00:54:49|         236|         229|   null|                B00254|\n",
      "|              B00445|2019-01-01 00:32:02|2019-01-01 00:56:51|         145|          16|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:25:50|2019-01-01 00:33:58|         171|          15|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:45:47|2019-01-01 01:03:04|         252|          82|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:36:25|2019-01-01 01:00:17|         265|          92|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:53:37|2019-01-01 01:37:09|         229|          15|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:36:15|2019-01-01 00:48:39|         171|          16|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:28:34|2019-01-01 00:39:40|          16|         252|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:12:32|2019-01-01 00:12:36|         252|          70|   null|                B00445|\n",
      "|              B00445|2019-01-01 00:45:07|2019-01-01 01:03:57|         265|         252|   null|                B00445|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the last 20 data to make sure it is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B03046|2019-01-10 23:35:00|2019-01-10 23:49:00|         265|         265|   null|                B03046|\n",
      "|              B03046|2019-01-10 23:15:00|2019-01-10 23:23:00|         265|         265|   null|                B03046|\n",
      "|              B03046|2019-01-10 23:03:00|2019-01-10 23:14:00|         265|         265|   null|                B03046|\n",
      "|              B03046|2019-01-10 23:00:00|2019-01-10 23:12:00|         265|         265|   null|                B03046|\n",
      "|              B03040|2019-01-10 23:48:22|2019-01-10 23:48:29|          48|         144|   null|                B03040|\n",
      "|              B03040|2019-01-10 23:21:30|2019-01-11 00:22:16|         230|         227|   null|                B03040|\n",
      "|              B03035|2019-01-10 23:13:15|2019-01-10 23:16:04|         264|         264|   null|                B00280|\n",
      "|              B03035|2019-01-10 23:29:09|2019-01-10 23:37:03|         264|         264|   null|                B02617|\n",
      "|              B03035|2019-01-10 23:31:03|2019-01-10 23:42:04|         264|         264|   null|                B02914|\n",
      "|              B03035|2019-01-10 23:47:03|2019-01-11 00:01:01|         264|         264|   null|                B02617|\n",
      "|              B03035|2019-01-10 23:09:16|2019-01-10 23:13:32|         264|         264|   null|                B02617|\n",
      "|              B03035|2019-01-10 23:39:26|2019-01-10 23:54:14|         264|         264|   null|                B02875|\n",
      "|              B03035|2019-01-10 23:50:10|2019-01-10 23:53:22|         264|         264|   null|                B02875|\n",
      "|              B03035|2019-01-10 23:51:40|2019-01-11 00:02:02|         264|         264|   null|                B02878|\n",
      "|              B03035|2019-01-10 23:20:11|2019-01-10 23:34:33|         264|         264|   null|                B02908|\n",
      "|              B03035|2019-01-10 23:27:33|2019-01-10 23:56:00|         264|         264|   null|                B02884|\n",
      "|              B03035|2019-01-10 23:09:40|2019-01-10 23:26:42|         264|         264|   null|                B02764|\n",
      "|              B03035|2019-01-10 23:43:50|2019-01-11 00:14:51|         264|         264|   null|                B00272|\n",
      "|              B03035|2019-01-10 23:11:06|2019-01-10 23:21:07|         264|         264|   null|                B00272|\n",
      "|              B03035|2019-01-10 23:38:57|2019-01-10 23:58:16|         264|         264|   null|                B02877|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = df_sql.withColumn(\"index\", monotonically_increasing_id())\n",
    "\n",
    "df_sql.orderBy(desc(\"index\")).drop(\"index\").show(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load: Write the data into a parquet and json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql.write.parquet(\"data/fhv_tripdata_between_2019-01-01_and_2019-01-10.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql.write.json(\"data/fhv_tripdata_between_2019-01-01_and_2019-01-10.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
